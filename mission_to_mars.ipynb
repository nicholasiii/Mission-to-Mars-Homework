{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from flask import Flask, jsonify, render_template, redirect\n",
    "import pymongo\n",
    "\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's Mars 2020 Rover Does Biceps Curls \n",
      "In this time-lapse video, the robotic arm on NASA's Mars 2020 rover maneuvers its 88-pound (40-kilogram) sensor-laden turret as it moves from a deployed to stowed configuration.\n"
     ]
    }
   ],
   "source": [
    "#* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text.\n",
    "#Loading page\n",
    "\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)\n",
    "\n",
    "# Not too fast...\n",
    "time.sleep(2)\n",
    "\n",
    "# Put it all in a soup\n",
    "html = browser.html  \n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Collect news and title\n",
    "news_title = soup.select('.grid_gallery.list_view li.slide .content_title a', limit=1)[0].contents[0]\n",
    "news_p = soup.select('.grid_gallery.list_view li.slide .article_teaser_body', limit=1)[0].contents[0]\n",
    "\n",
    "# Create a dictionary and add to return value dictionary\n",
    "mars_portal_info={}\n",
    "mars_portal_info[\"news_title\"] = news_title\n",
    "mars_portal_info[\"news_description\"] = news_p\n",
    "print(news_title)\n",
    "\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19968_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "#* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "# Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the \n",
    "#url string to a variable called `featured_image_url`.\n",
    "#Make sure to find the image url to the full size `.jpg` image.\n",
    "# Make sure to save a complete url string for this image.\n",
    "\n",
    "#\n",
    "#<article alt=\"Bright Penelope\" class=\"carousel_item\" style=\"background-image: \n",
    "#url('/spaceimages/images/wallpaper/PIA11591-1920x1200.jpg');\">\n",
    "#\n",
    "#becomes:\n",
    "# https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA11591_hires.jpg\n",
    "\n",
    "\n",
    "#Loading the website\n",
    "jpl_img_string=\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(jpl_img_string)\n",
    "# Wait for page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Sending it to soup\n",
    "html = browser.html  \n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Finding the image\n",
    "featim_rel = soup.select('div.carousel_container .floating_text_area footer a')[0][\"data-fancybox-href\"]\n",
    "featured_image_url = f\"https://www.jpl.nasa.gov{featim_rel}\"\n",
    "\n",
    "# Add to return value dictionary\n",
    "mars_portal_info[\"featured_image_url\"] = featured_image_url\n",
    "\n",
    "print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Mars Weather\n",
    "#* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars \n",
    "#weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "#\n",
    "#Get tweet page\n",
    "\n",
    "tweets_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(tweets_url)\n",
    "\n",
    "#Load it slow\n",
    "time.sleep(2)\n",
    "\n",
    "#Soup to read it\n",
    "html = browser.html  \n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Find all tweets on the page\n",
    "all_tweets = soup.select('.stream-items .js-stream-item .tweet .content p')\n",
    "\n",
    "# Loop through tweets to get the first actual weather report\n",
    "mars_weather = \"\"\n",
    "for result in all_tweets:\n",
    "    tweet_text = result.contents[0]\n",
    "    tweet_first_three = tweet_text[0:3]\n",
    "    if tweet_first_three == 'Sol':\n",
    "        mars_weather = tweet_text\n",
    "    break\n",
    "# Add to return value dictionary\n",
    "mars_portal_info[\"mars_weather\"] = mars_weather\n",
    "print(mars_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Visit the Mars Facts webpage [here](https://space-facts.com/mars/) and use Pandas to scrape the table containing \n",
    "#facts about the planet including Diameter, Mass, etc.\n",
    "#* Use Pandas to convert the data to a HTML table string.\n",
    "#\n",
    "#Getting table from site\n",
    "\n",
    "mars_facts_url=\"https://space-facts.com/mars/\"\n",
    "tables = pd.read_html(mars_facts_url)\n",
    "df = tables[0]\n",
    "\n",
    "# Moving it to a table\n",
    "mars_facts_table = df.to_html(buf=None, columns=None, col_space=None, header=False, index=False, \\\n",
    "na_rep='NaN', index_names=False, justify='right', bold_rows=True, classes=None, \\\n",
    "escape=True, max_rows=None, max_cols=None, show_dimensions=False, \\\n",
    "notebook=False, decimal='.', border=1)\n",
    "mars_portal_info[\"mars_facts_table\"] = mars_facts_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mars Hemispheres\n",
    "#* Visit the USGS Astrogeology site [here]\n",
    "#(https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars)\n",
    "#to obtain high resolution images for each of Mar's hemispheres.\n",
    "#* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution \n",
    "#image.\n",
    "#\n",
    "#https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n",
    "#\n",
    "#* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the \n",
    "#hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "#* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one \n",
    "#dictionary for each hemisphere.\n",
    "\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif\": \"...\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "## Step 2 - MongoDB and Flask Application\n",
    "#\n",
    "#Use MongoDB with Flask templating to create a new HTML page that displays all of the information that was scraped from\n",
    "#the URLs above.\n",
    "#\n",
    "#* Start by converting your Jupyter notebook into a Python script called `scrape_mars.py` with a function called \n",
    "#`scrape` that will execute all of your \n",
    "#scraping code from above and return one Python dictionary containing all of the scraped data.\n",
    "#\n",
    "#* Next, create a route called `/scrape` that will import your `scrape_mars.py` script and call your `scrape` function.\n",
    "#\n",
    "#  * Store the return value in Mongo as a Python dictionary.\n",
    "#\n",
    "#* Create a root route `/` that will query your Mongo database and pass the mars data into an HTML template to display\n",
    "#the data.\n",
    "#\n",
    "#* Create a template HTML file called `index.html` that will take the mars data dictionary and display all of the data\n",
    "#in the appropriate HTML elements. Use the following as a guide for what the final product should look like, but feel \n",
    "#free to create your own design.\n",
    "#\n",
    "#![final_app_part1.png](Images/final_app_part1.png)\n",
    "#![final_app_part2.png](Images/final_app_part2.png)\n",
    "\n",
    "# Starting stuff\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Routes\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    mars_index_info = mongo.db.mars_db.find_one()\n",
    "    return render_template(\"index.html\", portal_info=mars_index_info)\n",
    "\n",
    "# Putting the data into mars_db and the routes\n",
    "@app.route(\"/scrape\")\n",
    "def scrape():\n",
    "    # Grab dictionary of scraped values from function\n",
    "    marsportal_scraped_values = scrape_mars.scrape()   # THE REAL THING\n",
    "\n",
    "    # Declare the database\n",
    "    mars_db = mongo.db.mars_db\n",
    "\n",
    "    # Insert (or update) the document containing our dictionary into the database\n",
    "    mars_db.update(\n",
    "        {},\n",
    "        marsportal_scraped_values,\n",
    "        upsert=True\n",
    "    )\n",
    "    # Redirect to the home page to pass MongoDB values into our HTML template\n",
    "    return redirect(\"http://localhost:5000/\", code=302)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
